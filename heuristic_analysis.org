#+OPTIONS: toc:nil author:nil creator:nil
#+LaTeX_HEADER: \author{J\"org D\"opfert}
#+LaTeX_CLASS_OPTIONS: [11pt]
#+LaTeX_HEADER: \usepackage[a4paper, total={150mm,237mm}, left=30mm, top=20mm]{geometry}
 
 

#+TITLE: Planning (Lesson 11): Heuristic Analysis

* Custom evaluation heuristics
First I defined the following heuristic function templates:

 + *=moves_heuristic=*
   - This heuristic is a weighted sum of the number of moves available
     to the two players. It is calculated as $w_{\mathrm{own}} \cdot
     m_{\mathrm{own}}  + w_{\mathrm{opp}} \cdot  m_{\mathrm{opp}}$,
     where $m$ are the number of moves available and $w$ are the
     weights. Note that for $w_{\mathrm{opp}}=-1$ and
     $w_{\mathrm{own}}=1$, this heuristic is identical to the
     =improved_score()= heuristic given in the code template.

 + *=center_distance_heuristic=*
   - This heuristic is a weighted sum of the distances of the player's
     positions to the board center. It is calculated as $w_{\mathrm{own}} \cdot
     d_{\mathrm{own}}  + w_{\mathrm{opp}} \cdot  d_{\mathrm{opp}}$,
     where $d$ are the distances to the board center and $w$ are the
     weights. Optionally, the distances $d$ can be normalized by the
     maximum possible distance from the center on the board.


\noindent Then, I utilized and combined these templates in different ways
to create custom heuristic functions like so:

 - *=aggressive_move_heuristic=*
   - =moves_heuristic= with $w_{\mathrm{opp}}=-2.5$ and
     $w_{\mathrm{own}}=1$. This should drive the agent to aggressively
     reduce the number of moves available to the opponent, while
     maximizing its own movement possibilities.

 - *=relaxed_move_heuristic=*
   - =moves_heuristic= with $w_{\mathrm{opp}}=-0.5$ and
     $w_{\mathrm{own}}=1$. This should again drive the agent 
     reduce the number of moves available to the opponent, but less aggressively.

 - *=relaxed_move_relaxed_distance=*
   - This heuristic is the sum of the =relaxed_move_heuristic= above
     and the =center_distance_heuristic= with weights $w_{\mathrm{opp}}=0.75$ and
     $w_{\mathrm{own}}=-1.5$ to penalize positions far away from the
     board center (which are closer to the board's edges/corners), and
     slightly rewarding the opponent being in such positions.

 - *=relaxed_move_aggressive_distance=*
   - This heuristic is the sum of the =relaxed_move_heuristic= above
     and the =center_distance_heuristic= with weights $w_{\mathrm{opp}}=3$ and
     $w_{\mathrm{own}}=-1.5$ to again penalize positions far away from the
     board center and to aggressively drive the opponent to such positions.

 - *=relaxed_move_relaxed_distance_norm=*
   - Same as =relaxed_move_relaxed_distance=, but with normalized
     center distances. This will probably decrease the influence of the
     =center_distance_heuristic= in the beginning of the game, when
     there are still many moves available to both players.

 - *=relaxed_move_aggressive_distance_norm=*
   - Same as =relaxed_move_aggressive_distance=, but with normalized
     center distances.

* Performance of the heuristics
After defining the above custom heuristics, I evaluated them against the
=ID_Improved= agent in =tournament.py= and recorded the =win_ratio=
score returned from =play_round()=. To be more confident about the
resulting scores, I increased the =NUM_MATCHES= parameter to 50.


\noindent The results are summarized in the following table and Fig. [[fig:fig1]].

#+begin_src python :exports results :results raw :noweb strip-export
<<preamble>>
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.drop('Actions', 1)
cols = ['Problem', 'Search Method', 'Plan Lenght', 'Time', 'New Nodes', 'Goal Tests']
df['Search Method'] = df['Search Method'].str.replace('_', ' ')
df['Problem'] = df['Problem'].str.replace('Air Cargo Problem', '')
df['Time'] = np.round(df['Time'], 2)
df = df.sort_values(['Problem', 'Search Method'])
df = df[cols].set_index('Problem')
return(tabulate(df, headers="keys", tablefmt="orgtbl"))
#+end_src

#+LABEL:   tab:tab1
#+CAPTION: Performance of the different custom heuristics.
#+ATTR_LATEX: :align ll|cccc :placement [t]
#+RESULTS:
| Problem | Search Method                  | Plan Lenght |    Time | New Nodes | Goal Tests |
|---------+--------------------------------+-------------+---------+-----------+------------|
|       1 | breadth first search           |           6 |    0.04 |       180 |         56 |
|       1 | breadth first tree search      |           6 |    1.13 |      5960 |       1459 |
|       1 | depth first graph search       |          12 |    0.01 |        48 |         13 |
|       1 | depth limited search           |          50 |    0.11 |       414 |        271 |
|       1 | greedy best first graph search |           6 |    0.01 |        28 |          9 |
|       1 | uniform cost search            |           6 |    0.04 |       224 |         57 |
|       2 | breadth first search           |           9 |   15.96 |     30509 |       4609 |
|       2 | depth first graph search       |         575 |    3.51 |      5211 |        583 |
|       2 | depth limited search           |          50 | 1147.65 |   2054119 |    2053741 |
|       2 | greedy best first graph search |          17 |     8.8 |      8910 |        992 |
|       2 | uniform cost search            |           9 |   74.66 |     44030 |       4854 |
|       3 | breadth first search           |          12 |  123.53 |    129631 |      18098 |
|       3 | depth first graph search       |         596 |       4 |      5176 |        628 |
|       3 | greedy best first graph search |          22 |  128.96 |     49429 |       5616 |
|       3 | uniform cost search            |          12 |  489.38 |    159716 |      18237 |


According to the table, all the custom heuristics outperform =ID Improved=,
however, the differences in scores are pretty small. For a proper
assessment, statistical tests and probably an even higher number of
=NUM_MATCHES= would be required. 


#+HEADER: :var path="data/analysis.pdf"
#+begin_src python :exports results :results file :noweb strip-export
<<preamble>>
sns.set_context("talk")
    
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
g = sns.factorplot(data=df, hue='Search Method', y='Time', x='Problem',
                   kind='bar', legend=False)
g.fig.get_axes()[0].set_yscale('log')
#g.set_xticklabels(rotation=45)
plt.legend(loc='upper left')

#plt.gcf().tight_layout()
fig = plt.gcf()
fig.set_size_inches(11, 6)
fig.savefig(path)
return path # return filename to org-mode
#+end_src
#+LABEL:   fig:fig1
#+CAPTION: Performance of the different custom heuristics.
#+ATTR_LATEX: :width 12cm :placement [h!]
#+RESULTS:
[[file:data/analysis.pdf]]

* Conclusion
Based on these preliminary results in the previous section, 
I recommend using the \newline{} =relaxed_move_aggressive_distance_norm=
heuristic and also implemented it as the =custom_score()= in
=game_agent.py=. However, I am by no means sure if this is the best
heuristic among the tested ones, since the differences in the score
from the experiments are rather small.

The rather small differences could stem from the fact that the number
of moves available and the center distance are probably somewhat
correlated: The further away a player is from the center, the less
room there is for possible moves. Therefore, the all the heuristics
probably catch rather similar things.

Apart from defining and testing other heuristic functions, next steps
could include:

+ a proper statistical analysis of the results
+ evaluating the results of the custom agents against the different
  agents defined in =tournament.py= separately 
+ letting the agents with the different custom heuristics play against
  each other


* code blocks                                                      :noexport:

#+NAME: preamble
#+BEGIN_SRC python :results file :exports code 
import matplotlib
import numpy as np
import seaborn as sns
import pandas as pd

matplotlib.use('Agg')

import matplotlib.pyplot as plt

from tabulate import tabulate 

#+END_SRC
