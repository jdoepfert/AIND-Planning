#+OPTIONS: toc:nil author:nil creator:nil
#+LaTeX_HEADER: \author{J\"org D\"opfert}
#+LaTeX_CLASS_OPTIONS: [11pt]
#+LaTeX_HEADER: \usepackage[a4paper, total={150mm,242mm}, left=30mm, top=20mm]{geometry}
#+LaTeX_HEADER: \usepackage{caption} 

#+BEGIN_LaTeX
\captionsetup[table]{skip=8pt}
#+END_LaTeX
 

#+TITLE: Planning (Lesson 11): Heuristic Analysis



I begin this report with an evaluation of the results of selected search
methods. Optimal plans can be found in Section [[Optimal plans]], and detailed
metrics for all problems in consideration are displayed in Table [[tab:tab1]].

* Evaluation of the search methods

In Figure [[fig:time]], the run times of selected searches are displayed for all three
air cargo problems. Note that only for problem 1 all searches
finished in less than 10 minutes (no data was collected for searches that
took longer).  

#+HEADER: :var path="data/time.pdf"
#+begin_src python :exports results :results file :noweb strip-export
<<preamble>>
<<preproc_plot>>
g = sns.factorplot(data=df, hue='Search Method', y='Time [sec]', x='Problem',
                   kind='bar', legend=False)
g.fig.get_axes()[0].set_yscale('log')
plt.legend(loc='upper left')
<<postamble_plot>>
#+end_src
#+LABEL:   fig:time
#+CAPTION: Search run time.
#+ATTR_LATEX: :width 12cm :placement [h!]
#+RESULTS:
[[file:data/time.pdf]]


Among the fastest searches for all problems are =depth first graph search= and
=greedy best first graph search=. However, those methodes do not find
optimal plans in general, as can be seen in Figure [[fig:planlen]] (both
methods have a larger plan lenghts than the optimal =breadth first
search= solution for problems 2 and 3).


 The =breadth first search=  always finds an optimal plan, but at the
expense of speed: It is always slower than for example =depth first graph search=
since it expands much more nodes (compare Figure [[fig:nodes]]). The
slowest uninformed search seems to be =breadth first tree search=: It
expands a lot of nodes, since it does not keep track of nodes that
have already been visited.


#+HEADER: :var path="data/panlen.pdf"
#+begin_src python :exports results :results file :noweb strip-export
<<preamble>>
<<preproc_plot>>
g = sns.factorplot(data=df, hue='Search Method', y='Plan Length', x='Problem',
                   kind='bar', legend=False)
g.fig.get_axes()[0].set_yscale('log')
plt.legend(loc='upper left')
<<postamble_plot>>
#+end_src
#+LABEL:   fig:planlen
#+CAPTION: Number of steps in the solution plan
#+ATTR_LATEX: :width 12cm :placement [h!]
#+RESULTS:
[[file:data/panlen.pdf]]


#+HEADER: :var path="data/nodes.pdf"
#+begin_src python :exports results :results file :noweb strip-export
<<preamble>>
<<preproc_plot>>
g = sns.factorplot(data=df, hue='Search Method', y='Expansions', x='Problem',
                   kind='bar', legend=False)
g.fig.get_axes()[0].set_yscale('log')
plt.legend(loc='upper left')
<<postamble_plot>>
#+end_src
#+LABEL:   fig:nodes
#+CAPTION: Number of expanded nodes.
#+ATTR_LATEX: :width 12cm :placement [h!]
#+RESULTS:
[[file:data/nodes.pdf]]

Compared to =uniform cost search=, which is also guaranteed to find
an optimal solution, =breadth first search= is a bit faster and also
explores less nodes for all problems.

The =uniform cost search= and =a star search h1= explore the same amount
of nodes, since they are virtually identical: The former choses the
node with the cheapest path cost, and the latter choses the node with
the cheapest path cost plus a constant.

The informed searches =astar search pg levelsum= and =astar search
ignore precond= perform similar on problem 1 in terms of computation
time. However, the former expands much less nodes: This is expected,
since the =levelsum= heuristic calculated using a planning graph
should be much stronger than simply ignoring the action preconditions.


The =astar search pg levelsum= search did not finish below 10 minutes
on problem 3, and the =astar search ignore precond= search not even on
problem 2. For the former, this probably due to the
computational power required for building the planning graphs. For the
latter, this might be due to my inefficient implementation: I use a
breadth first search to find the solution lengths of the relaxed
problem without action preconditions. This could probably be
implemented much faster, especially if one assumes that the subgoal
are independent.


The informed searches find optimal plans for problem 1 and 2. For the
=astar search ignore precond=, this is a general result, since it uses
an admissible heuristic. The =astar search pg levelsum= is not
neccessarily admissible, but has shown good performance according to
the AIMA book.

The informed searches expand less nodes than the optimal uniformed
searches, as expected (this could only be fully assessed for problem 1 due
to missing data). However, when it comes to speed, the informed
searches are worse than the uninformed ones. Again, this could be
attributed to the large overhead for building the planning graphs and
my inefficient implementation of the "ignore preconditions" heuristic.


* Optimal plans

The plans presented here reflect the solutions found with
breadth first search (which always finds the optimal solution).

** Problem 1

#+begin_src python :exports results :noweb strip-export
<<preamble>>
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.sort_values(['Problem'])
df = df[df['Search Method'] == 'breadth_first_search']
df.Actions = df.Actions.apply(lambda x: "\n".join(x))
return df.Actions.iloc[0]
#+end_src

#+RESULTS:
: Load(C2, P2, JFK)
: Load(C1, P1, SFO)
: Fly(P2, JFK, SFO)
: Unload(C2, P2, SFO)
: Fly(P1, SFO, JFK)
: Unload(C1, P1, JFK)

** Problem 2

#+begin_src python :exports results :noweb strip-export
<<preamble>>
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.sort_values(['Problem'])
df = df[df['Search Method'] == 'breadth_first_search']
df.Actions = df.Actions.apply(lambda x: "\n".join(x))
return df.Actions.iloc[1]
#+end_src

#+RESULTS:
: Load(C2, P2, JFK)
: Load(C1, P1, SFO)
: Load(C3, P3, ATL)
: Fly(P2, JFK, SFO)
: Unload(C2, P2, SFO)
: Fly(P1, SFO, JFK)
: Unload(C1, P1, JFK)
: Fly(P3, ATL, SFO)
: Unload(C3, P3, SFO)

** Problem 3

#+begin_src python :exports results :noweb strip-export
<<preamble>>
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.sort_values(['Problem'])
df = df[df['Search Method'] == 'breadth_first_search']
df.Actions = df.Actions.apply(lambda x: "\n".join(x))
return df.Actions.iloc[2]
#+end_src

#+RESULTS:
#+begin_example
Load(C2, P2, JFK)
Load(C1, P1, SFO)
Fly(P2, JFK, ORD)
Load(C4, P2, ORD)
Fly(P1, SFO, ATL)
Load(C3, P1, ATL)
Fly(P1, ATL, JFK)
Unload(C1, P1, JFK)
Unload(C3, P1, JFK)
Fly(P2, ORD, SFO)
Unload(C2, P2, SFO)
Unload(C4, P2, SFO)
#+end_example



* All metrics 
Metrics for all problems in consideration are displayed in Table
[[tab:tab1]].

#+BEGIN_LaTeX
\hspace*{-1cm}
#+END_LaTeX

#+begin_src python :exports results :results raw :noweb strip-export
<<preamble>>
def custom_round(x):
    if isinstance(x, str):
        return x
    else:
        return np.round(x, 2)
    
filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.drop('Actions', 1)
cols = ['Problem', 'Search Method', 'Plan Lenght', 'Time [sec]', 'New Nodes', 'Goal Tests', 'Expansions']
df['Search Method'] = df['Search Method'].str.replace('_', ' ')
df['Search Method'] = df['Search Method'].str.replace('h ignore preconditions', 'ignore precond')
df['Search Method'] = df['Search Method'].str.replace('greedy best first graph search', 'greedy bfgs')
df = df[df['Search Method'] != 'depth limited search']
df['Problem'] = df['Problem'].str.replace('Air Cargo Problem', '')
df['Time'] = df['Time'].apply(custom_round)
df = df.rename(columns={'Time': 'Time [sec]'})
df = df.sort_values(['Problem', 'Search Method'])
df = df[cols].set_index('Problem')
return(tabulate(df, headers="keys", tablefmt="orgtbl"))
#+end_src

#+LABEL:   tab:tab1
#+CAPTION: Performance of the different custom heuristics.
#+ATTR_LATEX: :align cl|ccccc :placement [h] :font \small \hspace*{-1cm}
#+RESULTS:
| Problem | Search Method               | Plan Lenght | Time [sec] | New Nodes | Goal Tests | Expansions |
|---------+-----------------------------+-------------+------------+-----------+------------+------------|
|       1 | astar search h 1            |           6 |       0.05 |       224 |         57 |         55 |
|       1 | astar search h pg levelsum  |           6 |       2.06 |        50 |         13 |         11 |
|       1 | astar search ignore precond |           6 |       2.21 |       170 |         43 |         41 |
|       1 | breadth first search        |           6 |       0.04 |       180 |         56 |         43 |
|       1 | breadth first tree search   |           6 |       1.08 |      5960 |       1459 |       1458 |
|       1 | depth first graph search    |          12 |       0.01 |        48 |         13 |         12 |
|       1 | depth limited search        |          50 |       0.11 |       414 |        271 |        101 |
|       1 | greedy bfgs h 1             |           6 |       0.01 |        28 |          9 |          7 |
|       1 | uniform cost search         |           6 |       0.05 |       224 |         57 |         55 |
|       2 | astar search h 1            |           9 |      66.63 |     44030 |       4854 |       4852 |
|       2 | astar search h pg levelsum  |           - |          - |         - |          - |          - |
|       2 | astar search ignore precond |           - |          - |         - |          - |          - |
|       2 | breadth first search        |           9 |      15.96 |     30509 |       4609 |       3343 |
|       2 | breadth first tree search   |           - |          - |         - |          - |          - |
|       2 | depth first graph search    |         575 |       3.56 |      5211 |        583 |        582 |
|       2 | depth limited search        |          50 |    1067.59 |   2054119 |    2053741 |     222719 |
|       2 | greedy bfgs h 1             |          17 |       9.17 |      8910 |        992 |        990 |
|       2 | uniform cost search         |           9 |      49.08 |     44030 |       4854 |       4852 |
|       3 | astar search h 1            |          12 |      597.8 |    159716 |      18237 |      18235 |
|       3 | astar search h pg levelsum  |           - |          - |         - |          - |          - |
|       3 | astar search ignore precond |           - |          - |         - |          - |          - |
|       3 | breadth first search        |          12 |     119.31 |    129631 |      18098 |      14663 |
|       3 | breadth first tree search   |           - |          - |         - |          - |          - |
|       3 | depth first graph search    |         596 |       3.62 |      5176 |        628 |        627 |
|       3 | depth limited search        |           - |          - |         - |          - |          - |
|       3 | greedy bfgs h 1             |          22 |     154.53 |     49429 |       5616 |       5614 |
|       3 | uniform cost search         |          12 |     444.72 |    159716 |      18237 |      18235 |

#+BEGIN_LaTeX
\end{adjustwidth} 
#+END_LaTeX


* code blocks                                                      :noexport:

#+NAME: preamble
#+BEGIN_SRC python :results file :exports code 
import numpy as np
import pandas as pd

from tabulate import tabulate 

#+END_SRC


#+NAME: preproc_plot
#+BEGIN_SRC python :results file :exports code 
import matplotlib
import seaborn as sns
matplotlib.use('Agg')

import matplotlib.pyplot as plt

sns.set_context("talk")

def fill_nans(x):
    if x == '-':
        return np.nan
    return x

filename='data/non_heuristic_report.h5'
df = pd.read_hdf(filename)
df = df.drop('Actions', 1)
df = df.rename(columns={'Plan Lenght': 'Plan Length'})
cols = ['Problem', 'Search Method', 'Plan Length', 'Time [sec]', 'New Nodes', 'Goal Tests']
df['Search Method'] = df['Search Method'].str.replace('_', ' ')
df['Search Method'] = df['Search Method'].str.replace('h ignore preconditions', 'ignore precond')
df['Search Method'] = df['Search Method'].str.replace('greedy best first graph search', 'greedy bfgs')
df = df[df['Search Method'] != 'depth limited search']
# df['Problem'] = df['Problem'].str.replace('Air Cargo Problem', '')
df['Time'] = df['Time'].apply(fill_nans)
df['New Nodes'] = df['New Nodes'].apply(fill_nans)
df['Goal Tests'] = df['Goal Tests'].apply(fill_nans)
df['Plan Length'] = df['Plan Length'].apply(fill_nans)
df['Expansions'] = df['Expansions'].apply(fill_nans)
df = df.rename(columns={'Time': 'Time [sec]'})
df = df.sort_values(['Problem', 'Search Method'])
#+END_SRC


#+NAME: postamble_plot
#+BEGIN_SRC python :results file :exports code 
plt.xlabel('')
fig = plt.gcf()
fig.set_size_inches(12, 6)
fig.savefig(path, bbox_inches='tight')
return path # return filename to org-mode
#+END_SRC